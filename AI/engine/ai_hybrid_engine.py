"""
ðŸŒ AI Hybrid Engine - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‡Ø¬ÙŠÙ† (Groq + Local)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ÙˆØ¸ÙŠÙØ© Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù:
- Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø¨ÙŠÙ† Groq API ÙˆØ§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
- Ø§Ù„Ù€ Fallback Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù†Ø¯ ÙØ´Ù„ Groq
- Ø¶Ù…Ø§Ù† Ù†ÙØ³ Ø§Ù„ÙƒÙØ§Ø¡Ø© ÙÙŠ Ø§Ù„Ø­Ø§Ù„ØªÙŠÙ†

Created: 2025-11-01
Version: 1.0
"""

import json
import os
from typing import Dict, Any, Optional
from datetime import datetime


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ”§ CONFIGURATION - Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
GROQ_API_KEY = os.environ.get('GROQ_API_KEY', '')
GROQ_MODEL = "llama-3.3-70b-versatile"
GROQ_ENABLED = True
HYBRID_MODE = True  # Groq + Local
FALLBACK_TO_LOCAL = True  # Ø¹Ù†Ø¯ ÙØ´Ù„ Groq


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸŒ HYBRID ENGINE - Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‡Ø¬ÙŠÙ†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HybridAIEngine:
    """
    Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‡Ø¬ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠ
    
    ÙŠØ³ØªØ®Ø¯Ù… Groq Ø¹Ù†Ø¯ Ø§Ù„ØªÙˆÙØ±
    ÙŠØ±Ø¬Ø¹ Ù„Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„ÙØ´Ù„
    """
    
    def __init__(self):
        self.groq_enabled = GROQ_ENABLED
        self.groq_failures = []
        self.last_mode = None
    
    def chat(self, message: str, system_context: str, conversation_history: list = None) -> Dict[str, Any]:
        """
        Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù‡Ø¬ÙŠÙ†Ø©
        
        Args:
            message: Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            system_context: Ø³ÙŠØ§Ù‚ Ø§Ù„Ù†Ø¸Ø§Ù…
            conversation_history: ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        
        Returns:
            {
                'response': 'Ø§Ù„Ø±Ø¯',
                'mode': 'groq' Ø£Ùˆ 'local',
                'confidence': 0-100,
                'sources': []
            }
        """
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© 1: Groq API
        if self.groq_enabled and GROQ_API_KEY:
            groq_result = self._try_groq(message, system_context, conversation_history)
            
            if groq_result['success']:
                self.last_mode = 'groq'
                return {
                    'response': groq_result['response'],
                    'mode': 'groq',
                    'confidence': 95,
                    'sources': ['Groq API - Llama 3.3 70B'],
                    'processing_time': groq_result.get('time', 0)
                }
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© 2: Local Fallback
        local_result = self._use_local(message, system_context)
        
        self.last_mode = 'local'
        return {
            'response': local_result['response'],
            'mode': 'local',
            'confidence': local_result['confidence'],
            'sources': local_result['sources'],
            'fallback_reason': local_result.get('reason', 'Groq unavailable')
        }
    
    def _try_groq(self, message: str, system_context: str, history: list = None) -> Dict[str, Any]:
        """
        Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Groq API
        
        Returns:
            {
                'success': True/False,
                'response': 'Ø§Ù„Ø±Ø¯',
                'time': 0.5
            }
        """
        try:
            import requests
            import time
            
            start_time = time.time()
            
            url = "https://api.groq.com/openai/v1/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
            messages = [
                {"role": "system", "content": system_context}
            ]
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ§Ø±ÙŠØ®
            if history:
                messages.extend(history[-10:])  # Ø¢Ø®Ø± 10 Ø±Ø³Ø§Ø¦Ù„
            
            # Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            messages.append({"role": "user", "content": message})
            
            data = {
                "model": GROQ_MODEL,
                "messages": messages,
                "temperature": 0.3,
                "max_tokens": 2000,
                "top_p": 0.9
            }
            
            response = requests.post(url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                ai_response = result['choices'][0]['message']['content']
                
                processing_time = time.time() - start_time
                
                return {
                    'success': True,
                    'response': ai_response,
                    'time': processing_time
                }
            else:
                # ÙØ´Ù„ Groq
                self.groq_failures.append({
                    'timestamp': datetime.now().isoformat(),
                    'status_code': response.status_code,
                    'error': response.text[:200]
                })
                
                return {
                    'success': False,
                    'error': f'Groq API error: {response.status_code}'
                }
        
        except requests.exceptions.Timeout:
            self.groq_failures.append({
                'timestamp': datetime.now().isoformat(),
                'error': 'Timeout'
            })
            
            return {
                'success': False,
                'error': 'Groq timeout'
            }
        
        except Exception as e:
            self.groq_failures.append({
                'timestamp': datetime.now().isoformat(),
                'error': str(e)
            })
            
            return {
                'success': False,
                'error': str(e)
            }
    
    def _use_local(self, message: str, system_context: str) -> Dict[str, Any]:
        """
        Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        
        Ù†ÙØ³ Ø§Ù„ÙƒÙØ§Ø¡Ø© - Ø¨Ø¯ÙˆÙ† Groq
        """
        from AI.engine.ai_conversation import match_local_response
        from AI.engine.ai_database_search import search_database_for_query
        from AI.engine.ai_accounting_professional import get_professional_accounting_knowledge
        
        # 1. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„Ø³Ø±ÙŠØ¹ Ø§Ù„Ù…Ø­Ù„ÙŠ
        quick_response = match_local_response(message)
        if quick_response:
            return {
                'response': quick_response,
                'confidence': 100,
                'sources': ['Local FAQ - Fast Response'],
                'reason': 'Quick local match'
            }
        
        # 2. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        db_results = search_database_for_query(message)
        
        # 3. Ø¨Ù†Ø§Ø¡ Ø±Ø¯ Ù…Ø­Ù„ÙŠ Ø°ÙƒÙŠ
        local_response = self._build_smart_local_response(message, db_results)
        
        return {
            'response': local_response['text'],
            'confidence': local_response['confidence'],
            'sources': local_response['sources'],
            'reason': 'Local intelligence'
        }
    
    def _build_smart_local_response(self, message: str, db_results: Dict) -> Dict[str, Any]:
        """
        Ø¨Ù†Ø§Ø¡ Ø±Ø¯ Ø°ÙƒÙŠ Ù…Ø­Ù„ÙŠØ§Ù‹
        
        ÙŠØ­Ù„Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆÙŠØ¨Ù†ÙŠ Ø±Ø¯ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¨Ø¯ÙˆÙ† Groq
        """
        message_lower = message.lower()
        
        # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        intent = db_results.get('intent', {})
        
        # Ø±Ø¯ÙˆØ¯ Ø°ÙƒÙŠØ© Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        if intent.get('type') == 'count':
            # Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø¯
            response_parts = ['ðŸ“Š **Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:**\n']
            
            for key, value in db_results.items():
                if key.endswith('_count') and isinstance(value, int):
                    label = key.replace('_count', '').replace('_', ' ').title()
                    response_parts.append(f'â€¢ {label}: {value:,}')
            
            return {
                'text': '\n'.join(response_parts),
                'confidence': 90,
                'sources': ['Database Query', 'Local Intelligence']
            }
        
        elif intent.get('type') == 'balance':
            # Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø£Ø±ØµØ¯Ø©
            return {
                'text': """ðŸ“Š **Ø´Ø±Ø­ Ø§Ù„Ø£Ø±ØµØ¯Ø©:**

ðŸ”µ **Ø±ØµÙŠØ¯ Ø§Ù„Ø¹Ù…ÙŠÙ„:**
Ø§Ù„ØµÙŠØºØ©: (Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª + Ø§Ù„ÙÙˆØ§ØªÙŠØ± + Ø§Ù„Ø®Ø¯Ù…Ø§Øª) - (Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø§Ù„ÙˆØ§Ø±Ø¯Ø©)
â€¢ Ø³Ø§Ù„Ø¨ (-) = ðŸ”´ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù„ÙŠÙ‡ ÙŠØ¯ÙØ¹
â€¢ Ù…ÙˆØ¬Ø¨ (+) = ðŸŸ¢ Ù„Ù„Ø¹Ù…ÙŠÙ„ Ø±ØµÙŠØ¯ Ø¹Ù†Ø¯Ù†Ø§

ðŸ”µ **Ø±ØµÙŠØ¯ Ø§Ù„Ù…ÙˆØ±Ø¯:**
Ø§Ù„ØµÙŠØºØ©: (Ø§Ù„Ù…Ø´ØªØ±ÙŠØ§Øª + Ø§Ù„Ø´Ø­Ù†Ø§Øª) - (Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø§Ù„ØµØ§Ø¯Ø±Ø©)
â€¢ Ø³Ø§Ù„Ø¨ (-) = ðŸ”´ Ø¹Ù„ÙŠÙ†Ø§ Ù†Ø¯ÙØ¹ Ù„Ù„Ù…ÙˆØ±Ø¯
â€¢ Ù…ÙˆØ¬Ø¨ (+) = ðŸŸ¢ Ø¯ÙØ¹Ù†Ø§ Ø²ÙŠØ§Ø¯Ø©

Ù‡Ù„ ØªØ±ÙŠØ¯ Ø´Ø±Ø­ Ø±ØµÙŠØ¯ Ù…Ø¹ÙŠÙ†ØŸ Ø£Ø¹Ø·Ù†ÙŠ Ø±Ù‚Ù… Ø§Ù„Ø¹Ù…ÙŠÙ„/Ø§Ù„Ù…ÙˆØ±Ø¯.""",
                'confidence': 100,
                'sources': ['Accounting Knowledge Base', 'Memory']
            }
        
        else:
            # Ø±Ø¯ Ø¹Ø§Ù… Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            response = f"ðŸ¤– **ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ù„ÙŠ:**\n\n"
            response += f"Ø§Ù„Ø³Ø¤Ø§Ù„: {message}\n\n"
            
            if db_results:
                response += "ðŸ“Š **Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:**\n"
                for key, value in list(db_results.items())[:5]:
                    if key != 'intent':
                        response += f"â€¢ {key}: {value}\n"
            
            response += "\nðŸ’¡ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø£ÙƒØ«Ø± - ÙˆØ¶Ù‘Ø­ Ø·Ù„Ø¨Ùƒ Ø£Ùˆ Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¨Ø´ÙƒÙ„ Ù…Ø­Ø¯Ø¯."
            
            return {
                'text': response,
                'confidence': 70,
                'sources': ['Database', 'Local Analysis']
            }
    
    def get_status(self) -> Dict[str, Any]:
        """Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‡Ø¬ÙŠÙ†"""
        return {
            'groq_enabled': self.groq_enabled,
            'last_mode': self.last_mode,
            'groq_failures': len(self.groq_failures),
            'recent_failures': self.groq_failures[-5:] if self.groq_failures else [],
            'hybrid_mode': HYBRID_MODE,
            'fallback_enabled': FALLBACK_TO_LOCAL
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸŽ¯ SINGLETON INSTANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_hybrid_engine = None

def get_hybrid_engine() -> HybridAIEngine:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‡Ø¬ÙŠÙ† (Singleton)"""
    global _hybrid_engine
    
    if _hybrid_engine is None:
        _hybrid_engine = HybridAIEngine()
    
    return _hybrid_engine


__all__ = [
    'HybridAIEngine',
    'get_hybrid_engine',
    'GROQ_API_KEY',
    'GROQ_ENABLED'
]

