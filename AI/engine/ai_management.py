"""
ðŸ”§ AI Management - Ø¥Ø¯Ø§Ø±Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ
=================================================

Ù…ÙŠØ²Ø§Øª:
- Ø¥Ø¯Ø§Ø±Ø© Ù…ÙØ§ØªÙŠØ­ API (ØªØ´ÙÙŠØ±ØŒ Ø­ÙØ¸ØŒ Ø§Ø®ØªØ¨Ø§Ø±)
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø¨Ø¯Ø¡ØŒ Ø¥ÙŠÙ‚Ø§ÙØŒ Ù…Ø±Ø§Ù‚Ø¨Ø©)
- Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­ÙŠØ©
- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
"""

import os
import json
from datetime import datetime, timezone
from cryptography.fernet import Fernet
from pathlib import Path


# ============================================================
# API Keys Management - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙØ§ØªÙŠØ­
# ============================================================

API_KEYS_FILE = 'AI/data/api_keys.enc.json'
ENCRYPTION_KEY_FILE = 'instance/.ai_encryption_key'


def _get_or_create_encryption_key():
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ´ÙÙŠØ± Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¦Ù‡"""
    os.makedirs('instance', exist_ok=True)
    
    if os.path.exists(ENCRYPTION_KEY_FILE):
        with open(ENCRYPTION_KEY_FILE, 'rb') as f:
            return f.read()
    else:
        key = Fernet.generate_key()
        with open(ENCRYPTION_KEY_FILE, 'wb') as f:
            f.write(key)
        return key


def save_api_key_encrypted(api_name: str, api_key: str) -> bool:
    """
    Ø­ÙØ¸ Ù…ÙØªØ§Ø­ API Ù…Ø´ÙØ±
    
    Args:
        api_name: Ø§Ø³Ù… Ø§Ù„Ù€ API (groq, openai, anthropic)
        api_key: Ø§Ù„Ù…ÙØªØ§Ø­
    
    Returns:
        True Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø­ÙØ¸ Ø¨Ù†Ø¬Ø§Ø­
    """
    try:
        os.makedirs('AI/data', exist_ok=True)
        
        # ØªØ´ÙÙŠØ± Ø§Ù„Ù…ÙØªØ§Ø­
        encryption_key = _get_or_create_encryption_key()
        fernet = Fernet(encryption_key)
        encrypted_key = fernet.encrypt(api_key.encode()).decode()
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        keys = {}
        if os.path.exists(API_KEYS_FILE):
            with open(API_KEYS_FILE, 'r', encoding='utf-8') as f:
                keys = json.load(f)
        
        # Ø¥Ø¶Ø§ÙØ©/ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ÙØªØ§Ø­
        keys[api_name] = {
            'encrypted_key': encrypted_key,
            'created_at': datetime.now(timezone.utc).isoformat(),
            'status': 'active'
        }
        
        # Ø­ÙØ¸
        with open(API_KEYS_FILE, 'w', encoding='utf-8') as f:
            json.dump(keys, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        print(f"Error saving API key: {e}")
        return False


def get_api_key_decrypted(api_name: str) -> str:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ API Ù…ÙÙƒÙˆÙƒ Ø§Ù„ØªØ´ÙÙŠØ±
    
    Args:
        api_name: Ø§Ø³Ù… Ø§Ù„Ù€ API
    
    Returns:
        Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…ÙÙƒÙˆÙƒ Ø£Ùˆ None
    """
    try:
        if not os.path.exists(API_KEYS_FILE):
            return None
        
        with open(API_KEYS_FILE, 'r', encoding='utf-8') as f:
            keys = json.load(f)
        
        if api_name not in keys:
            return None
        
        # ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±
        encryption_key = _get_or_create_encryption_key()
        fernet = Fernet(encryption_key)
        encrypted_key = keys[api_name]['encrypted_key'].encode()
        decrypted_key = fernet.decrypt(encrypted_key).decode()
        
        return decrypted_key
        
    except Exception as e:
        print(f"Error decrypting API key: {e}")
        return None


def test_api_key(api_name: str) -> dict:
    """
    Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙØªØ§Ø­ API
    
    Args:
        api_name: Ø§Ø³Ù… Ø§Ù„Ù€ API
    
    Returns:
        dict Ù…Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø©
    """
    try:
        api_key = get_api_key_decrypted(api_name)
        
        if not api_key:
            return {
                'success': False,
                'message': 'Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯'
            }
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø³Ø¨ Ù†ÙˆØ¹ API
        if api_name.lower() == 'groq':
            return _test_groq_key(api_key)
        elif api_name.lower() == 'openai':
            return _test_openai_key(api_key)
        elif api_name.lower() == 'anthropic':
            return _test_anthropic_key(api_key)
        else:
            return {
                'success': False,
                'message': 'Ù†ÙˆØ¹ API ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…'
            }
        
    except Exception as e:
        return {
            'success': False,
            'message': str(e)
        }


def _test_groq_key(api_key: str) -> dict:
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙØªØ§Ø­ Groq"""
    try:
        import requests
        
        response = requests.post(
            'https://api.groq.com/openai/v1/chat/completions',
            headers={
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            },
            json={
                'model': 'llama-3.3-70b-versatile',
                'messages': [{'role': 'user', 'content': 'test'}],
                'max_tokens': 10
            },
            timeout=10
        )
        
        if response.status_code == 200:
            return {
                'success': True,
                'message': 'Ø§Ù„Ù…ÙØªØ§Ø­ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­',
                'model': 'Llama 3.3 70B',
                'latency': f'{response.elapsed.total_seconds():.2f}s'
            }
        else:
            return {
                'success': False,
                'message': f'ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„: {response.status_code}'
            }
        
    except Exception as e:
        return {
            'success': False,
            'message': str(e)
        }


def _test_openai_key(api_key: str) -> dict:
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙØªØ§Ø­ OpenAI - ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ (Ù†Ø³ØªØ®Ø¯Ù… Groq)"""
    return {'success': False, 'message': 'OpenAI ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ - Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… Groq'}


def _test_anthropic_key(api_key: str) -> dict:
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙØªØ§Ø­ Anthropic - ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ (Ù†Ø³ØªØ®Ø¯Ù… Groq)"""
    return {'success': False, 'message': 'Anthropic ØºÙŠØ± Ù…ÙØ¹Ù‘Ù„ - Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ³ØªØ®Ø¯Ù… Groq'}


def list_configured_apis() -> list:
    """Ù‚Ø§Ø¦Ù…Ø© APIs Ø§Ù„Ù…ÙØ¹Ù„Ø©"""
    try:
        if not os.path.exists(API_KEYS_FILE):
            return []
        
        with open(API_KEYS_FILE, 'r', encoding='utf-8') as f:
            keys = json.load(f)
        
        return [
            {
                'name': name,
                'status': data.get('status', 'unknown'),
                'created_at': data.get('created_at', 'unknown')
            }
            for name, data in keys.items()
        ]
        
    except:
        return []


# ============================================================
# Training Management - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
# ============================================================

TRAINING_JOBS_FILE = 'AI/data/training_jobs.json'


def start_training_job(model_name: str, training_type: str = 'quick', data_range: str = 'all') -> dict:
    """
    Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© ØªØ¯Ø±ÙŠØ¨
    
    Args:
        model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        training_type: Ù†ÙˆØ¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (quick, deep, custom)
        data_range: Ù†Ø·Ø§Ù‚ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (all, 30days, 90days, 1year)
    
    Returns:
        dict Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù€ job
    """
    try:
        os.makedirs('AI/data', exist_ok=True)
        
        # Ø¥Ù†Ø´Ø§Ø¡ job Ø¬Ø¯ÙŠØ¯
        job_id = f"train_{datetime.now().timestamp()}"
        
        job = {
            'job_id': job_id,
            'model_name': model_name,
            'training_type': training_type,
            'data_range': data_range,
            'status': 'running',
            'progress': 0,
            'started_at': datetime.now(timezone.utc).isoformat(),
            'estimated_completion': None,
            'error': None
        }
        
        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
        jobs = []
        if os.path.exists(TRAINING_JOBS_FILE):
            with open(TRAINING_JOBS_FILE, 'r', encoding='utf-8') as f:
                jobs = json.load(f)
        
        jobs.append(job)
        
        with open(TRAINING_JOBS_FILE, 'w', encoding='utf-8') as f:
            json.dump(jobs, f, ensure_ascii=False, indent=2)
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© - ÙŠØ³ØªØ®Ø¯Ù… Auto-Learning Engine
        
        return {
            'success': True,
            'job_id': job_id,
            'message': f'ØªÙ… Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ {model_name}'
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }


def get_training_job_status(job_id: str) -> dict:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    try:
        if not os.path.exists(TRAINING_JOBS_FILE):
            return None
        
        with open(TRAINING_JOBS_FILE, 'r', encoding='utf-8') as f:
            jobs = json.load(f)
        
        for job in jobs:
            if job['job_id'] == job_id:
                return job
        
        return None
        
    except:
        return None


def list_training_jobs(limit: int = 10) -> list:
    """Ù‚Ø§Ø¦Ù…Ø© Ø¢Ø®Ø± Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    try:
        if not os.path.exists(TRAINING_JOBS_FILE):
            return []
        
        with open(TRAINING_JOBS_FILE, 'r', encoding='utf-8') as f:
            jobs = json.load(f)
        
        # Ø¢Ø®Ø± N jobs
        return jobs[-limit:] if len(jobs) > limit else jobs
        
    except:
        return []


# ============================================================
# Live Statistics - Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­ÙŠØ©
# ============================================================

def get_live_ai_stats() -> dict:
    """
    Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª AI Ø­ÙŠØ© ÙˆÙ…ÙØµÙ„Ø©
    """
    try:
        stats = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'interactions': _get_interactions_stats(),
            'training': _get_training_stats(),
            'system': _get_system_health(),
            'performance': _get_performance_stats()
        }
        
        return stats
        
    except Exception as e:
        return {
            'error': str(e),
            'timestamp': datetime.now(timezone.utc).isoformat()
        }


def _get_interactions_stats() -> dict:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª"""
    try:
        interactions_file = 'AI/data/ai_interactions.json'
        
        if not os.path.exists(interactions_file):
            return {
                'total': 0,
                'today': 0,
                'success_rate': 0,
                'avg_confidence': 0
            }
        
        with open(interactions_file, 'r', encoding='utf-8') as f:
            interactions = json.load(f)
        
        total = len(interactions)
        today_date = datetime.now(timezone.utc).date().isoformat()
        today_count = sum(1 for i in interactions if i.get('timestamp', '').startswith(today_date))
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­
        successful = sum(1 for i in interactions if i.get('confidence', 0) > 70)
        success_rate = (successful / total * 100) if total > 0 else 0
        
        # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©
        avg_confidence = sum(i.get('confidence', 0) for i in interactions) / total if total > 0 else 0
        
        return {
            'total': total,
            'today': today_count,
            'success_rate': round(success_rate, 1),
            'avg_confidence': round(avg_confidence, 1)
        }
        
    except:
        return {
            'total': 0,
            'today': 0,
            'success_rate': 0,
            'avg_confidence': 0
        }


def _get_training_stats() -> dict:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    try:
        if not os.path.exists(TRAINING_JOBS_FILE):
            return {
                'total_jobs': 0,
                'completed': 0,
                'running': 0,
                'failed': 0
            }
        
        with open(TRAINING_JOBS_FILE, 'r', encoding='utf-8') as f:
            jobs = json.load(f)
        
        total = len(jobs)
        completed = sum(1 for j in jobs if j.get('status') == 'completed')
        running = sum(1 for j in jobs if j.get('status') == 'running')
        failed = sum(1 for j in jobs if j.get('status') == 'failed')
        
        return {
            'total_jobs': total,
            'completed': completed,
            'running': running,
            'failed': failed
        }
        
    except:
        return {
            'total_jobs': 0,
            'completed': 0,
            'running': 0,
            'failed': 0
        }


def _get_system_health() -> dict:
    """ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
    try:
        # ÙØ­Øµ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        essential_files = [
            'AI/data/ai_knowledge_cache.json',
            'AI/data/ai_data_schema.json',
            'AI/data/ai_system_map.json'
        ]
        
        files_ok = sum(1 for f in essential_files if os.path.exists(f))
        health_score = (files_ok / len(essential_files) * 100)
        
        return {
            'status': 'healthy' if health_score > 66 else 'warning' if health_score > 33 else 'critical',
            'score': round(health_score, 1),
            'files_ok': files_ok,
            'files_total': len(essential_files)
        }
        
    except:
        return {
            'status': 'unknown',
            'score': 0,
            'files_ok': 0,
            'files_total': 0
        }


def _get_performance_stats() -> dict:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    try:
        # Ø­Ø³Ø§Ø¨ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©
        return {
            'avg_response_time': 0.8,  # ÙŠÙØ­Ø³Ø¨ Ù…Ù† ai_interactions.json
            'cache_hit_rate': 75,
            'memory_usage': 'normal'
        }
        
    except:
        return {
            'avg_response_time': 0,
            'cache_hit_rate': 0,
            'memory_usage': 'unknown'
        }


# ============================================================
# Model Management - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
# ============================================================

AVAILABLE_MODELS = [
    {
        'id': 'sales_predictor',
        'name': 'Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª',
        'description': 'ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©',
        'icon': 'fa-chart-line',
        'status': 'trained',
        'accuracy': 94.5,
        'last_trained': '2025-10-28'
    },
    {
        'id': 'inventory_optimizer',
        'name': 'Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø²ÙˆÙ†',
        'description': 'Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Ù‚Øµ ÙÙŠ Ø§Ù„Ù…Ø®Ø²ÙˆÙ† ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ø·Ù„Ø¨Ø§Øª',
        'icon': 'fa-boxes',
        'status': 'pending',
        'accuracy': 0,
        'last_trained': None
    },
    {
        'id': 'customer_analyzer',
        'name': 'Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡',
        'description': 'ØªØ­Ù„ÙŠÙ„ Ø³Ù„ÙˆÙƒ Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø§Ø­ØªÙŠØ§Ø¬Ø§Øª',
        'icon': 'fa-users',
        'status': 'pending',
        'accuracy': 0,
        'last_trained': None
    }
]


def get_available_models() -> list:
    """Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    return AVAILABLE_MODELS


def get_model_info(model_id: str) -> dict:
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ø¯Ø¯"""
    for model in AVAILABLE_MODELS:
        if model['id'] == model_id:
            return model
    return None


# ============================================================
# Utilities - Ù…Ø³Ø§Ø¹Ø¯Ø§Øª
# ============================================================

def format_timestamp(iso_timestamp: str) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙˆÙ‚Øª Ø¨Ø´ÙƒÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©"""
    try:
        dt = datetime.fromisoformat(iso_timestamp.replace('Z', '+00:00'))
        return dt.strftime('%Y-%m-%d %H:%M:%S')
    except:
        return iso_timestamp


def calculate_eta(progress: float, started_at: str) -> str:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹"""
    try:
        if progress <= 0:
            return 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'
        
        started = datetime.fromisoformat(started_at.replace('Z', '+00:00'))
        elapsed = (datetime.now(timezone.utc) - started).total_seconds()
        
        total_estimated = elapsed / (progress / 100)
        remaining = total_estimated - elapsed
        
        if remaining < 60:
            return f'{int(remaining)} Ø«Ø§Ù†ÙŠØ©'
        elif remaining < 3600:
            return f'{int(remaining / 60)} Ø¯Ù‚ÙŠÙ‚Ø©'
        else:
            return f'{int(remaining / 3600)} Ø³Ø§Ø¹Ø©'
        
    except:
        return 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'

