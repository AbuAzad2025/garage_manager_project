"""
ðŸ—„ï¸ AI Database Expert - Ø®Ø¨ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ÙˆØ¸ÙŠÙØ© Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù:
- ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SQL
- Ø§ÙƒØªØ´Ø§Ù Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
- Ø§Ù‚ØªØ±Ø§Ø­ indexes
- ØªØ­Ù„ÙŠÙ„ database schema
- Query optimization

Created: 2025-11-01
Version: Database Expert 1.0 - MASTER LEVEL
"""

from typing import Dict, List, Any, Optional, Tuple
from sqlalchemy import inspect, text
from extensions import db
import re


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸ—„ï¸ DATABASE EXPERT ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DatabaseExpert:
    """
    Ø®Ø¨ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ø¨Ù‚Ø±ÙŠ
    
    Ø§Ù„Ù‚Ø¯Ø±Ø§Øª:
    1. ØªØ­Ù„ÙŠÙ„ ÙˆØªØ­Ø³ÙŠÙ† SQL queries
    2. Ø§ÙƒØªØ´Ø§Ù N+1 problems
    3. Ø§Ù‚ØªØ±Ø§Ø­ indexes
    4. ØªØ­Ù„ÙŠÙ„ performance
    5. Database design review
    6. Migration suggestions
    """
    
    def __init__(self):
        self.common_patterns = self._load_common_patterns()
    
    def analyze_query(self, query: str) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL
        
        Args:
            query: Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL
        
        Returns:
            ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª
        """
        analysis = {
            'query': query,
            'issues': [],
            'performance_score': 100,
            'suggestions': [],
            'optimized_query': None,
            'estimated_complexity': 'O(1)'
        }
        
        # ÙØ­Øµ SELECT *
        if 'SELECT *' in query.upper():
            analysis['issues'].append({
                'type': 'bad_practice',
                'severity': 'medium',
                'message': 'Ø§Ø³ØªØ®Ø¯Ø§Ù… SELECT * - Ø­Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙ‚Ø·',
                'fix': 'Ø§Ø³ØªØ¨Ø¯Ù„ * Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©'
            })
            analysis['performance_score'] -= 10
        
        # ÙØ­Øµ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ WHERE
        if 'WHERE' not in query.upper() and 'SELECT' in query.upper():
            analysis['issues'].append({
                'type': 'missing_where',
                'severity': 'high',
                'message': 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ WHERE clause - Ù‚Ø¯ ÙŠØ¹ÙŠØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª',
                'fix': 'Ø£Ø¶Ù WHERE Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©'
            })
            analysis['performance_score'] -= 20
            analysis['estimated_complexity'] = 'O(n) - Full table scan'
        
        # ÙØ­Øµ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ LIMIT
        if 'LIMIT' not in query.upper() and 'SELECT' in query.upper():
            analysis['suggestions'].append(
                'Ø£Ø¶Ù LIMIT Ù„Ù„Ø­Ø¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ø¯Ø©'
            )
        
        # ÙØ­Øµ JOIN performance
        join_count = query.upper().count('JOIN')
        if join_count > 3:
            analysis['issues'].append({
                'type': 'many_joins',
                'severity': 'medium',
                'message': f'Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† JOINs ({join_count}) - Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡',
                'fix': 'ÙÙƒØ± ÙÙŠ Ø¥Ø¹Ø§Ø¯Ø© ØªØµÙ…ÙŠÙ… Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… subqueries'
            })
            analysis['performance_score'] -= (join_count - 3) * 5
        
        # ÙØ­Øµ Ø§Ø³ØªØ®Ø¯Ø§Ù… LIKE %...%
        if re.search(r"LIKE\s+['\"]%.*%['\"]", query, re.IGNORECASE):
            analysis['issues'].append({
                'type': 'slow_like',
                'severity': 'high',
                'message': 'LIKE %...% Ø¨Ø·ÙŠØ¡ Ø¬Ø¯Ø§Ù‹ - Ù„Ø§ ÙŠØ³ØªØ®Ø¯Ù… index',
                'fix': 'Ø§Ø³ØªØ®Ø¯Ù… Full-Text Search Ø£Ùˆ Ø§Ø¨Ø¯Ø£ Ø§Ù„Ù†Ù…Ø· Ø¨Ø­Ø±Ù Ø«Ø§Ø¨Øª'
            })
            analysis['performance_score'] -= 25
        
        # ÙØ­Øµ OR ÙÙŠ WHERE
        or_count = len(re.findall(r'\bOR\b', query, re.IGNORECASE))
        if or_count > 2:
            analysis['suggestions'].append(
                f'Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† OR ({or_count}) - ÙÙƒØ± ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… IN Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†Ù‡Ø§'
            )
        
        # ÙØ­Øµ Subqueries
        if 'SELECT' in query[10:]:  # subquery
            analysis['suggestions'].append(
                'Ø§Ø³ØªØ®Ø¯Ø§Ù… subquery - ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ù…Ø«Ù„ (ÙÙƒØ± ÙÙŠ JOIN)'
            )
        
        return analysis
    
    def suggest_index(self, table_name: str, query_pattern: str) -> List[Dict]:
        """Ø§Ù‚ØªØ±Ø§Ø­ indexes"""
        suggestions = []
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¹Ù…Ø¯Ø© WHERE
        where_match = re.search(r'WHERE\s+(\w+)', query_pattern, re.IGNORECASE)
        if where_match:
            column = where_match.group(1)
            suggestions.append({
                'type': 'single_column_index',
                'table': table_name,
                'columns': [column],
                'sql': f'CREATE INDEX idx_{table_name}_{column} ON {table_name}({column});',
                'reason': f'Ù„ØªØ³Ø±ÙŠØ¹ WHERE {column}'
            })
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¹Ù…Ø¯Ø© JOIN
        join_matches = re.findall(r'JOIN\s+\w+\s+ON\s+\w+\.(\w+)', query_pattern, re.IGNORECASE)
        for column in join_matches:
            suggestions.append({
                'type': 'foreign_key_index',
                'table': table_name,
                'columns': [column],
                'sql': f'CREATE INDEX idx_{table_name}_{column}_fk ON {table_name}({column});',
                'reason': f'Ù„ØªØ³Ø±ÙŠØ¹ JOIN Ø¹Ù„Ù‰ {column}'
            })
        
        return suggestions
    
    def detect_n_plus_one(self, code_context: str) -> Optional[Dict]:
        """Ø§ÙƒØªØ´Ø§Ù N+1 problem"""
        # Ù†Ù…Ø·: for loop Ù…Ø¹ query Ø¯Ø§Ø®Ù„Ù‡Ø§
        pattern = r'for\s+\w+\s+in\s+.*:\s*\n.*\.query\.'
        
        if re.search(pattern, code_context, re.MULTILINE):
            return {
                'detected': True,
                'issue': 'N+1 Query Problem',
                'explanation': '''
ÙŠØªÙ… ØªÙ†ÙÙŠØ° query Ù…Ù†ÙØµÙ„ Ù„ÙƒÙ„ Ø¹Ù†ØµØ± ÙÙŠ Ø§Ù„Ù€ loop.

Ù…Ø«Ø§Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:
```python
customers = Customer.query.all()  # 1 query
for customer in customers:
    sales = customer.sales  # N queries (ÙˆØ§Ø­Ø¯ Ù„ÙƒÙ„ customer)
```

Ø§Ù„Ø­Ù„:
```python
# Ø§Ø³ØªØ®Ø¯Ù… joinedload Ø£Ùˆ subqueryload
from sqlalchemy.orm import joinedload

customers = Customer.query.options(
    joinedload(Customer.sales)
).all()  # 1 query ÙÙ‚Ø·

for customer in customers:
    sales = customer.sales  # Ù„Ø§ ØªÙˆØ¬Ø¯ queries Ø¥Ø¶Ø§ÙÙŠØ©
```
                ''',
                'solution': 'Ø§Ø³ØªØ®Ø¯Ù… eager loading: joinedload() Ø£Ùˆ subqueryload()'
            }
        
        return None
    
    def analyze_schema(self, table_name: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ schema Ø§Ù„Ø¬Ø¯ÙˆÙ„"""
        try:
            inspector = inspect(db.engine)
            
            # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            columns = inspector.get_columns(table_name)
            
            # Foreign Keys
            fks = inspector.get_foreign_keys(table_name)
            
            # Indexes
            indexes = inspector.get_indexes(table_name)
            
            analysis = {
                'table_name': table_name,
                'total_columns': len(columns),
                'total_fks': len(fks),
                'total_indexes': len(indexes),
                'issues': [],
                'recommendations': []
            }
            
            # ÙØ­Øµ: Ø¬Ø¯ÙˆÙ„ Ø¨Ø¯ÙˆÙ† primary key
            pk = inspector.get_pk_constraint(table_name)
            if not pk.get('constrained_columns'):
                analysis['issues'].append({
                    'type': 'no_primary_key',
                    'severity': 'critical',
                    'message': 'Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Primary Key'
                })
            
            # ÙØ­Øµ: FK Ø¨Ø¯ÙˆÙ† index
            fk_columns = set()
            for fk in fks:
                for col in fk.get('constrained_columns', []):
                    fk_columns.add(col)
            
            indexed_columns = set()
            for idx in indexes:
                for col in idx.get('column_names', []):
                    indexed_columns.add(col)
            
            unindexed_fks = fk_columns - indexed_columns
            if unindexed_fks:
                analysis['recommendations'].append({
                    'type': 'add_fk_indexes',
                    'message': f'Ø£Ø¶Ù indexes Ø¹Ù„Ù‰ FK: {", ".join(unindexed_fks)}'
                })
            
            # ÙØ­Øµ: Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
            if len(columns) > 30:
                analysis['recommendations'].append({
                    'type': 'normalize_table',
                    'message': f'Ø§Ù„Ø¬Ø¯ÙˆÙ„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {len(columns)} Ø¹Ù…ÙˆØ¯ - ÙÙƒØ± ÙÙŠ normalization'
                })
            
            # ÙØ­Øµ: Ø£Ø¹Ù…Ø¯Ø© nullable ÙƒØ«ÙŠØ±Ø©
            nullable_count = sum(1 for col in columns if col.get('nullable', True))
            if nullable_count > len(columns) * 0.7:
                analysis['recommendations'].append({
                    'type': 'reduce_nullables',
                    'message': f'{nullable_count} Ø¹Ù…ÙˆØ¯ nullable - ÙÙƒØ± ÙÙŠ Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©'
                })
            
            return analysis
        
        except Exception as e:
            return {'error': str(e)}
    
    def suggest_query_optimization(self, slow_query: str) -> Dict[str, Any]:
        """Ø§Ù‚ØªØ±Ø§Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ø¨Ø·ÙŠØ¡"""
        optimizations = []
        optimized = slow_query
        
        # 1. Ø§Ø³ØªØ¨Ø¯Ø§Ù„ SELECT *
        if 'SELECT *' in optimized.upper():
            optimizations.append({
                'type': 'specific_columns',
                'before': 'SELECT *',
                'after': 'SELECT column1, column2, ...',
                'benefit': 'ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ù‚ÙˆÙ„Ø©'
            })
        
        # 2. Ø¥Ø¶Ø§ÙØ© LIMIT
        if 'LIMIT' not in optimized.upper():
            optimizations.append({
                'type': 'add_limit',
                'before': optimized,
                'after': optimized + ' LIMIT 100',
                'benefit': 'ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬'
            })
        
        # 3. Ø§Ø³ØªØ®Ø¯Ø§Ù… EXISTS Ø¨Ø¯Ù„ COUNT
        if 'COUNT(*)' in optimized.upper() and 'WHERE' in optimized.upper():
            optimizations.append({
                'type': 'use_exists',
                'before': 'SELECT COUNT(*) FROM table WHERE condition',
                'after': 'SELECT EXISTS(SELECT 1 FROM table WHERE condition LIMIT 1)',
                'benefit': 'EXISTS Ø£Ø³Ø±Ø¹ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙˆØ¬ÙˆØ¯'
            })
        
        # 4. Ø§Ø³ØªØ®Ø¯Ø§Ù… IN Ø¨Ø¯Ù„ OR
        or_count = len(re.findall(r'\bOR\b', optimized, re.IGNORECASE))
        if or_count > 2:
            optimizations.append({
                'type': 'use_in',
                'before': 'WHERE col = 1 OR col = 2 OR col = 3',
                'after': 'WHERE col IN (1, 2, 3)',
                'benefit': 'IN Ø£ÙˆØ¶Ø­ ÙˆØ£Ø³Ø±Ø¹'
            })
        
        return {
            'original_query': slow_query,
            'optimizations': optimizations,
            'estimated_improvement': f'{len(optimizations) * 15}%'
        }
    
    def _load_common_patterns(self) -> Dict:
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"""
        return {
            'slow_patterns': [
                r'SELECT \* FROM',
                r'LIKE ["\']%.*%["\']',
                r'OR.*OR.*OR'
            ],
            'good_patterns': [
                r'SELECT \w+, \w+ FROM',
                r'WHERE.*LIMIT',
                r'.*INDEX'
            ]
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ðŸŽ¯ SINGLETON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_db_expert = None

def get_database_expert() -> DatabaseExpert:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø®Ø¨ÙŠØ± Database (Singleton)"""
    global _db_expert
    
    if _db_expert is None:
        _db_expert = DatabaseExpert()
    
    return _db_expert


__all__ = [
    'DatabaseExpert',
    'get_database_expert'
]

