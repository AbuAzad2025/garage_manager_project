"""
ğŸ§¬ AI Self-Evolution Engine - Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø°Ø§ØªÙŠ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ÙˆØ¸ÙŠÙØ© Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù:
- ØªØ·ÙˆØ± Ø°Ø§ØªÙŠ Ù…Ø³ØªÙ…Ø±
- Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
- ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
- Ø§ÙƒØªØ´Ø§Ù Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù
- ØªØ·ÙˆÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©

Created: 2025-11-01
Version: Evolution 1.0 - GENIUS LEVEL
"""

import os
import json
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from collections import Counter
import re


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“ FILE PATHS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EVOLUTION_LOG = 'AI/data/evolution_log.json'
ERROR_LEARNING_LOG = 'AI/data/error_learning.json'
PERFORMANCE_METRICS = 'AI/data/performance_metrics.json'
KNOWLEDGE_GAPS = 'AI/data/knowledge_gaps.json'


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§¬ SELF EVOLUTION ENGINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SelfEvolutionEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø°Ø§ØªÙŠ
    
    Ø§Ù„Ù‚Ø¯Ø±Ø§Øª:
    1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø°Ø§ØªÙŠ
    2. Ø§ÙƒØªØ´Ø§Ù Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù
    3. Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    4. ØªØ·ÙˆÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø©
    5. ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª
    6. Ù‚ÙŠØ§Ø³ Ø§Ù„Ø«Ù‚Ø©
    """
    
    def __init__(self):
        self.performance_history = []
        self.error_patterns = {}
        self.knowledge_gaps = []
        self.evolution_metrics = {
            'total_interactions': 0,
            'successful_responses': 0,
            'failed_responses': 0,
            'average_confidence': 0.0,
            'learning_rate': 0.0,
            'evolution_level': 1
        }
        self.load_state()
    
    def load_state(self):
        """ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ±"""
        try:
            if os.path.exists(PERFORMANCE_METRICS):
                with open(PERFORMANCE_METRICS, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.evolution_metrics = data.get('metrics', self.evolution_metrics)
                    self.performance_history = data.get('history', [])
        except Exception:
            pass
    
    def save_state(self):
        """Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ±"""
        try:
            os.makedirs('AI/data', exist_ok=True)
            
            with open(PERFORMANCE_METRICS, 'w', encoding='utf-8') as f:
                json.dump({
                    'metrics': self.evolution_metrics,
                    'history': self.performance_history[-1000:],  # Ø¢Ø®Ø± 1000
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[ERROR] Error saving evolution state: {e}")
    
    def record_interaction(self, query: str, response: Dict, success: bool, 
                          confidence: float, execution_time: float):
        """
        ØªØ³Ø¬ÙŠÙ„ ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        
        Args:
            query: Ø§Ù„Ø³Ø¤Ø§Ù„
            response: Ø§Ù„Ø±Ø¯
            success: Ù†Ø¬Ø­ Ø£Ù… ÙØ´Ù„
            confidence: Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© (0-1)
            execution_time: ÙˆÙ‚Øª Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ
        """
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.evolution_metrics['total_interactions'] += 1
        
        if success:
            self.evolution_metrics['successful_responses'] += 1
        else:
            self.evolution_metrics['failed_responses'] += 1
        
        # ØªØ­Ø¯ÙŠØ« Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©
        old_avg = self.evolution_metrics['average_confidence']
        total = self.evolution_metrics['total_interactions']
        new_avg = ((old_avg * (total - 1)) + confidence) / total
        self.evolution_metrics['average_confidence'] = round(new_avg, 4)
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…
        if len(self.performance_history) >= 100:
            recent_success_rate = sum(
                1 for p in self.performance_history[-100:] 
                if p.get('success')
            ) / 100
            
            old_success_rate = sum(
                1 for p in self.performance_history[-200:-100] 
                if p.get('success')
            ) / 100 if len(self.performance_history) >= 200 else 0.5
            
            self.evolution_metrics['learning_rate'] = round(
                (recent_success_rate - old_success_rate) * 100, 2
            )
        
        # ØªØ­Ø¯ÙŠØ« Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ·ÙˆØ±
        success_rate = (
            self.evolution_metrics['successful_responses'] / 
            self.evolution_metrics['total_interactions']
        )
        
        if success_rate >= 0.95 and self.evolution_metrics['average_confidence'] >= 0.85:
            self.evolution_metrics['evolution_level'] = 5  # Ø¹Ø¨Ù‚Ø±ÙŠ
        elif success_rate >= 0.90 and self.evolution_metrics['average_confidence'] >= 0.75:
            self.evolution_metrics['evolution_level'] = 4  # Ø®Ø¨ÙŠØ±
        elif success_rate >= 0.80 and self.evolution_metrics['average_confidence'] >= 0.65:
            self.evolution_metrics['evolution_level'] = 3  # Ù…ØªÙ‚Ø¯Ù…
        elif success_rate >= 0.70:
            self.evolution_metrics['evolution_level'] = 2  # Ù…ØªÙˆØ³Ø·
        else:
            self.evolution_metrics['evolution_level'] = 1  # Ù…Ø¨ØªØ¯Ø¦
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
        self.performance_history.append({
            'timestamp': datetime.now().isoformat(),
            'query': query[:200],  # Ø£ÙˆÙ„ 200 Ø­Ø±Ù
            'success': success,
            'confidence': confidence,
            'execution_time': execution_time,
            'response_length': len(str(response))
        })
        
        # Ø­ÙØ¸
        self.save_state()
        
        # ØªØ­Ù„ÙŠÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙØ´Ù„
        if not success:
            self.analyze_failure(query, response)
    
    def analyze_failure(self, query: str, response: Dict):
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ´Ù„ ÙˆØ§Ù„ØªØ¹Ù„Ù… Ù…Ù†Ù‡
        
        Args:
            query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø°ÙŠ ÙØ´Ù„
            response: Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙŠ ÙƒØ§Ù† Ø®Ø§Ø·Ø¦Ø§Ù‹
        """
        try:
            # ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø· Ø§Ù„Ø®Ø·Ø£
            error_type = self._categorize_error(query, response)
            
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ error patterns
            if error_type not in self.error_patterns:
                self.error_patterns[error_type] = {
                    'count': 0,
                    'examples': [],
                    'learned': False
                }
            
            self.error_patterns[error_type]['count'] += 1
            self.error_patterns[error_type]['examples'].append({
                'query': query[:200],
                'timestamp': datetime.now().isoformat()
            })
            
            # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 10 Ø£Ù…Ø«Ù„Ø©
            self.error_patterns[error_type]['examples'] = \
                self.error_patterns[error_type]['examples'][-10:]
            
            # Ø­ÙØ¸ ÙÙŠ ERROR_LEARNING_LOG
            self._save_error_learning()
            
            # Ø§ÙƒØªØ´Ø§Ù ÙØ¬ÙˆØ© Ù…Ø¹Ø±ÙÙŠØ©
            knowledge_gap = self._detect_knowledge_gap(query, error_type)
            if knowledge_gap:
                self.knowledge_gaps.append(knowledge_gap)
                self._save_knowledge_gaps()
        
        except Exception as e:
            print(f"[ERROR] Error analyzing failure: {e}")
    
    def _categorize_error(self, query: str, response: Dict) -> str:
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø®Ø·Ø£"""
        query_lower = query.lower()
        
        # Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        if any(word in query_lower for word in ['Ø±ØµÙŠØ¯', 'Ø­Ø³Ø§Ø¨', 'Ù…Ø¨Ù„Øº', 'balance']):
            return 'accounting_error'
        
        if any(word in query_lower for word in ['Ø¹Ù…ÙŠÙ„', 'Ù…ÙˆØ±Ø¯', 'Ø´Ø±ÙŠÙƒ', 'customer', 'supplier']):
            return 'entity_error'
        
        if any(word in query_lower for word in ['Ù…Ø®Ø²ÙˆÙ†', 'Ù…Ù†ØªØ¬', 'Ù‚Ø·Ø¹Ø©', 'stock', 'product']):
            return 'inventory_error'
        
        if any(word in query_lower for word in ['Ù‚ÙŠØ¯', 'Ù…Ø­Ø§Ø³Ø¨ÙŠ', 'Ø¯ÙØªØ±', 'gl', 'ledger']):
            return 'gl_error'
        
        if any(word in query_lower for word in ['Ø¶Ø±ÙŠØ¨Ø©', 'vat', 'tax']):
            return 'tax_error'
        
        return 'unknown_error'
    
    def _detect_knowledge_gap(self, query: str, error_type: str) -> Optional[Dict]:
        """Ø§ÙƒØªØ´Ø§Ù ÙØ¬ÙˆØ© Ù…Ø¹Ø±ÙÙŠØ©"""
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ø§ÙƒØªØ´Ø§Ù Ù…Ø§ ÙŠÙ†Ù‚Øµ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯
        
        gap = {
            'timestamp': datetime.now().isoformat(),
            'query': query[:200],
            'error_type': error_type,
            'gap_description': '',
            'priority': 'medium'
        }
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¬ÙˆØ©
        if error_type == 'accounting_error':
            gap['gap_description'] = 'Ù†Ù‚Øµ ÙÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ© Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª'
            gap['priority'] = 'high'
        
        elif error_type == 'tax_error':
            gap['gap_description'] = 'Ù†Ù‚Øµ ÙÙŠ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¶Ø±ÙŠØ¨ÙŠØ©'
            gap['priority'] = 'high'
        
        elif error_type == 'gl_error':
            gap['gap_description'] = 'Ù†Ù‚Øµ ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø§Ù„Ù…Ø­Ø§Ø³Ø¨ÙŠØ©'
            gap['priority'] = 'critical'
        
        else:
            gap['gap_description'] = 'ÙØ¬ÙˆØ© Ù…Ø¹Ø±ÙÙŠØ© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©'
            gap['priority'] = 'low'
        
        return gap
    
    def _save_error_learning(self):
        """Ø­ÙØ¸ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        try:
            os.makedirs('AI/data', exist_ok=True)
            
            with open(ERROR_LEARNING_LOG, 'w', encoding='utf-8') as f:
                json.dump({
                    'error_patterns': self.error_patterns,
                    'total_errors': sum(p['count'] for p in self.error_patterns.values()),
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[ERROR] Error saving error learning: {e}")
    
    def _save_knowledge_gaps(self):
        """Ø­ÙØ¸ ÙØ¬ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        try:
            os.makedirs('AI/data', exist_ok=True)
            
            with open(KNOWLEDGE_GAPS, 'w', encoding='utf-8') as f:
                json.dump({
                    'gaps': self.knowledge_gaps[-100:],  # Ø¢Ø®Ø± 100
                    'last_updated': datetime.now().isoformat()
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"[ERROR] Error saving knowledge gaps: {e}")
    
    def get_evolution_report(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ·ÙˆØ±"""
        success_rate = 0
        if self.evolution_metrics['total_interactions'] > 0:
            success_rate = (
                self.evolution_metrics['successful_responses'] / 
                self.evolution_metrics['total_interactions']
            ) * 100
        
        level_names = {
            1: 'ğŸŸ¡ Ù…Ø¨ØªØ¯Ø¦',
            2: 'ğŸŸ  Ù…ØªÙˆØ³Ø·',
            3: 'ğŸ”µ Ù…ØªÙ‚Ø¯Ù…',
            4: 'ğŸŸ£ Ø®Ø¨ÙŠØ±',
            5: 'ğŸ† Ø¹Ø¨Ù‚Ø±ÙŠ'
        }
        
        return {
            'evolution_level': self.evolution_metrics['evolution_level'],
            'evolution_level_name': level_names.get(
                self.evolution_metrics['evolution_level'], 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'
            ),
            'total_interactions': self.evolution_metrics['total_interactions'],
            'success_rate': round(success_rate, 2),
            'average_confidence': round(
                self.evolution_metrics['average_confidence'] * 100, 2
            ),
            'learning_rate': self.evolution_metrics['learning_rate'],
            'total_errors': sum(p['count'] for p in self.error_patterns.values()),
            'error_types': len(self.error_patterns),
            'knowledge_gaps': len(self.knowledge_gaps),
            'recent_performance': self._get_recent_performance()
        }
    
    def _get_recent_performance(self) -> Dict:
        """Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù€ 24 Ø³Ø§Ø¹Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©"""
        if not self.performance_history:
            return {
                'interactions': 0,
                'success_rate': 0,
                'avg_confidence': 0,
                'avg_response_time': 0
            }
        
        # Ø¢Ø®Ø± 24 Ø³Ø§Ø¹Ø©
        cutoff = datetime.now() - timedelta(hours=24)
        
        recent = [
            p for p in self.performance_history
            if datetime.fromisoformat(p['timestamp']) >= cutoff
        ]
        
        if not recent:
            return {
                'interactions': 0,
                'success_rate': 0,
                'avg_confidence': 0,
                'avg_response_time': 0
            }
        
        success_count = sum(1 for p in recent if p.get('success'))
        avg_confidence = sum(p.get('confidence', 0) for p in recent) / len(recent)
        avg_time = sum(p.get('execution_time', 0) for p in recent) / len(recent)
        
        return {
            'interactions': len(recent),
            'success_rate': round((success_count / len(recent)) * 100, 2),
            'avg_confidence': round(avg_confidence * 100, 2),
            'avg_response_time': round(avg_time, 3)
        }
    
    def suggest_improvements(self) -> List[str]:
        """Ø§Ù‚ØªØ±Ø§Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„Ù…"""
        suggestions = []
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        if self.error_patterns:
            most_common = sorted(
                self.error_patterns.items(),
                key=lambda x: x[1]['count'],
                reverse=True
            )[:3]
            
            for error_type, data in most_common:
                if data['count'] >= 5 and not data.get('learned'):
                    suggestions.append(
                        f"ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø±ÙØ© ÙÙŠ: {error_type} ({data['count']} Ø£Ø®Ø·Ø§Ø¡)"
                    )
        
        # ØªØ­Ù„ÙŠÙ„ ÙØ¬ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ©
        critical_gaps = [
            g for g in self.knowledge_gaps
            if g.get('priority') == 'critical'
        ]
        
        if len(critical_gaps) >= 3:
            suggestions.append(
                f"Ù‡Ù†Ø§Ùƒ {len(critical_gaps)} ÙØ¬ÙˆØ© Ù…Ø¹Ø±ÙÙŠØ© Ø­Ø±Ø¬Ø© ØªØ­ØªØ§Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø©"
            )
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
        if self.evolution_metrics['average_confidence'] < 0.7:
            suggestions.append(
                "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶ - ÙŠØ­ØªØ§Ø¬ ØªØ¯Ø±ÙŠØ¨ Ø¥Ø¶Ø§ÙÙŠ"
            )
        
        if self.evolution_metrics['learning_rate'] < 0:
            suggestions.append(
                "Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø³Ù„Ø¨ÙŠ - ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"
            )
        
        return suggestions


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ SINGLETON
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_evolution_engine = None

def get_evolution_engine() -> SelfEvolutionEngine:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø­Ø±Ùƒ Ø§Ù„ØªØ·ÙˆØ± (Singleton)"""
    global _evolution_engine
    
    if _evolution_engine is None:
        _evolution_engine = SelfEvolutionEngine()
    
    return _evolution_engine


__all__ = [
    'SelfEvolutionEngine',
    'get_evolution_engine'
]

