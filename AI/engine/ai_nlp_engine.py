"""
๐ง AI NLP Engine - ูุญุฑู ูุนุงูุฌุฉ ุงููุบุฉ ุงูุทุจูุนูุฉ
ุชุญููู ูุบูู ุฐูู - ููุณ ููุงุฆู ุบุจูุฉ!

ูููู:
- ุงูุณูุงู ูู ุงูุฌููุฉ ูุงููุฉ
- ุงูุนูุงูุงุช ุจูู ุงููููุงุช
- ุงููุนูู ุงูุญูููู ูููุณ ููุท ุงููููุงุช
- ุงูุฃูุนุงู ูุงูุฃุณูุงุก ูุงูุตูุงุช
- ุงูุชุฑููุจ ุงููุญูู
"""

import re
from typing import Dict, List, Any, Tuple, Optional

# ==================== ุชุญููู ุงูุจููุฉ ุงููุญููุฉ ====================

class ArabicSentenceAnalyzer:
    """ูุญูู ุงูุฌูู ุงูุนุฑุจูุฉ - ูููู ุงูุจููุฉ ุงููุญููุฉ"""
    
    def __init__(self):
        # ุฃููุงุท ุงูุฃูุนุงู ุงูุนุฑุจูุฉ
        self.verb_patterns = {
            'question': r'(ูู|ูุงุฐุง|ูุง|ูู|ุฃูู|ูุชู|ููู|ูู|ููุงุฐุง)',
            'command': r'(ุฃุนุทูู|ุฃุฑูู|ุงุนุฑุถ|ุงุญุณุจ|ุญูู|ุงูุญุต|ุฃูุดุฆ|ุฃุถู|ุงุญุฐู|ุนุฏู)',
            'request': r'(ุฃุฑูุฏ|ุฃุญุชุงุฌ|ูููู|ูู ุณูุญุช|ูู ูุถูู|ุนุงูุฒ|ุจุฏู)',
            'analysis': r'(ุญูู|ุงูุญุต|ุฑุงุฌุน|ูููู|ุงุฎุชุจุฑ|ุชุฃูุฏ)',
            'comparison': r'(ูุงุฑู|ุงููุฑู|ุฃูููุง|ุฃูุถู|ุฃุณูุฃ)',
            'search': r'(ุงุจุญุซ|ุฌุฏ|ููู|ููู|ุฃูู|ุฏููู|ูุตููู)',
        }
        
        # ุฃููุงุท ุงูููุงูุงุช
        self.entity_patterns = {
            'customer': r'(ุนููู|ุนููุงุก|ุฒุจูู|ุฒุจุงุฆู|ุงูุฒุจุงูู|ุงูุนููุงุก)',
            'money': r'(\d+[\d,]*\.?\d*)\s*(ุดููู|ุฏููุงุฑ|ุฏููุงุฑ|ููุฑู|โช|\$|โฌ)',
            'time': r'(ุงูููู|ุฃูุณ|ุบุฏุงู|ุงูุฃุณุจูุน|ุงูุดูุฑ|ุงูุณูุฉ|ูุฐุง\s+\w+)',
            'number': r'(\d+[\d,]*)',
            'percentage': r'(\d+\.?\d*)%',
        }
        
        # ูููุงุช ุงูุฑุจุท ูุงูุณูุงู
        self.context_words = {
            'positive': ['ููุชุงุฒ', 'ุฑุงุฆุน', 'ุฌูุฏ', 'ุนุธูู', 'ูุงุฌุญ', 'ูุจุฑูู'],
            'negative': ['ุณูุก', 'ูุงุดู', 'ุถุนูู', 'ูุดููุฉ', 'ุฎุทุฃ', 'ุนุทู'],
            'urgent': ['ุณุฑูุน', 'ุนุงุฌู', 'ููุฑู', 'ุงูุขู', 'ุญุงูุงู'],
            'polite': ['ูู ุณูุญุช', 'ูู ูุถูู', 'ุดูุฑุงู', 'ุฌุฒุงู ุงููู'],
        }
    
    def extract_verb_intent(self, text: str) -> Optional[str]:
        """ุงุณุชุฎุฑุงุฌ ุงูููุฉ ูู ุงููุนู ุงูุฑุฆูุณู"""
        text_lower = text.lower()
        
        for intent, pattern in self.verb_patterns.items():
            if re.search(pattern, text_lower):
                return intent
        
        # ุงุณุชูุชุงุฌ ูู ุงูุณูุงู
        if 'ุ' in text:
            return 'question'
        elif text.endswith('!'):
            return 'command'
        
        return None
    
    def extract_entities(self, text: str) -> Dict[str, List[Any]]:
        """ุงุณุชุฎุฑุงุฌ ุงูููุงูุงุช ูู ุงููุต"""
        entities = {}
        
        for entity_type, pattern in self.entity_patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                entities[entity_type] = matches
        
        return entities
    
    def detect_sentiment(self, text: str) -> str:
        """ูุดู ุงููุดุงุนุฑ ูู ุงูุณูุงู"""
        text_lower = text.lower()
        
        positive_count = sum(1 for word in self.context_words['positive'] if word in text_lower)
        negative_count = sum(1 for word in self.context_words['negative'] if word in text_lower)
        
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'
    
    def analyze(self, text: str) -> Dict[str, Any]:
        """ุชุญููู ุดุงูู ููุฌููุฉ"""
        return {
            'intent': self.extract_verb_intent(text),
            'entities': self.extract_entities(text),
            'sentiment': self.detect_sentiment(text),
            'has_question_mark': 'ุ' in text or '?' in text,
            'word_count': len(text.split()),
            'is_polite': any(word in text.lower() for word in self.context_words['polite']),
            'is_urgent': any(word in text.lower() for word in self.context_words['urgent']),
        }

# ==================== ููู ุงููุนูู ุงูุฏูุงูู ====================

class SemanticUnderstanding:
    """ููู ุงููุนูู ุงูุฏูุงูู - ููุณ ููุท ุงููููุงุช"""
    
    def __init__(self):
        # ุฎุฑูุทุฉ ุงูููุงููู (concepts)
        self.concepts = {
            'financial_performance': {
                'keywords': ['ุฑุจุญ', 'ุฎุณุงุฑุฉ', 'ูุจูุนุงุช', 'ุฅูุฑุงุฏุงุช', 'ูููุงุช', 'ุฏุฎู'],
                'related': ['ูุญุงุณุจุฉ', 'ูุงููุฉ', 'ุฃุฏุงุก'],
                'intent': 'analysis',
            },
            'customer_satisfaction': {
                'keywords': ['ุฑุถุง', 'ุดููู', 'ุชูููู', 'ุฎุฏูุฉ', 'ุฌูุฏุฉ'],
                'related': ['ุนููุงุก', 'ุชุฌุฑุจุฉ'],
                'intent': 'feedback',
            },
            'inventory_management': {
                'keywords': ['ูุฎุฒูู', 'ุจุถุงุนุฉ', 'ูุทุน', 'ููุชุฌุงุช', 'ููุงุฏ'],
                'related': ['ูุณุชูุฏุน', 'ุชููุฑ', 'ูููุฉ'],
                'intent': 'stock_check',
            },
            'performance_metrics': {
                'keywords': ['ุฃุฏุงุก', 'ูุณุจุฉ', 'ูุนุฏู', 'ููุงุกุฉ', 'ุฅูุชุงุฌูุฉ'],
                'related': ['ููุงุณ', 'ุชูููู', 'ูุคุดุฑ'],
                'intent': 'analysis',
            },
        }
    
    def find_concept(self, text: str) -> Optional[Tuple[str, float]]:
        """ุงูุนุซูุฑ ุนูู ุงูููููู ุงูุฃุณุงุณู ูู ุงููุต"""
        text_lower = text.lower()
        
        best_match = None
        best_score = 0
        
        for concept_name, concept_data in self.concepts.items():
            score = 0
            
            # ุชุทุงุจู ุงููููุงุช ุงูููุชุงุญูุฉ
            for keyword in concept_data['keywords']:
                if keyword in text_lower:
                    score += 2
            
            # ุชุทุงุจู ุงููููุงุช ุงููุฑุชุจุทุฉ
            for related in concept_data['related']:
                if related in text_lower:
                    score += 1
            
            if score > best_score:
                best_score = score
                best_match = concept_name
        
        if best_match and best_score > 0:
            return (best_match, best_score / 10.0)  # normalize to 0-1
        
        return None
    
    def understand_question(self, text: str) -> Dict[str, Any]:
        """ููู ุงูุณุคุงู ุจุดูู ุนููู"""
        concept = self.find_concept(text)
        
        understanding = {
            'main_concept': concept[0] if concept else None,
            'confidence': concept[1] if concept else 0.0,
            'is_comparative': any(word in text.lower() for word in ['ุฃูุถู', 'ุฃุณูุฃ', 'ููุงุฑูุฉ', 'ุงููุฑู']),
            'is_temporal': any(word in text.lower() for word in ['ุงูููู', 'ุฃูุณ', 'ุงูุฃุณุจูุน', 'ุงูุดูุฑ']),
            'is_quantitative': any(word in text.lower() for word in ['ูู', 'ุนุฏุฏ', 'ูุฌููุน', 'ูุชูุณุท']),
        }
        
        return understanding

# ==================== ุงุณุชูุชุงุฌ ุงูููุฉ ุงููุชูุฏู ====================

class AdvancedIntentDetector:
    """ูุงุดู ุงูููุฉ ุงููุชูุฏู - ูุณุชูุชุฌ ูููุณ ููุท ูุทุงุจู"""
    
    def __init__(self):
        self.sentence_analyzer = ArabicSentenceAnalyzer()
        self.semantic_engine = SemanticUnderstanding()
    
    def detect_intent(self, text: str) -> Dict[str, Any]:
        """ูุดู ุงูููุฉ ุจุฐูุงุก"""
        
        # ุชุญููู ุงูุฌููุฉ
        sentence_analysis = self.sentence_analyzer.analyze(text)
        
        # ููู ุงููุนูู
        semantic = self.semantic_engine.understand_question(text)
        
        # ุฏูุฌ ุงูุชุญูููุงุช
        intent_result = {
            'primary_intent': None,
            'secondary_intents': [],
            'confidence': 0.0,
            'reasoning': [],
        }
        
        # ุงูุงุณุชูุชุงุฌ ุงูููุทูู
        text_lower = text.lower()
        
        # 1. ุณุคุงู ููู (ุนุฏุฏุ ูุจูุบ)
        if semantic['is_quantitative'] or any(w in text_lower for w in ['ูู', 'ุนุฏุฏ']):
            intent_result['primary_intent'] = 'quantitative_query'
            intent_result['confidence'] = 0.9
            intent_result['reasoning'].append('ูุทูุจ ุฑููุงู ุฃู ุนุฏุฏุงู')
        
        # 2. ุชุญููู ูุชูููู
        elif semantic['main_concept'] in ['financial_performance', 'performance_metrics']:
            intent_result['primary_intent'] = 'performance_analysis'
            intent_result['confidence'] = 0.85
            intent_result['reasoning'].append('ูุทูุจ ุชุญููู ุฃุฏุงุก')
        
        # 3. ููุงุฑูุฉ
        elif semantic['is_comparative']:
            intent_result['primary_intent'] = 'comparison'
            intent_result['confidence'] = 0.9
            intent_result['reasoning'].append('ููุงุฑู ุจูู ุดูุฆูู')
        
        # 4. ุจุญุซ ูุชููู
        elif sentence_analysis['intent'] == 'search':
            intent_result['primary_intent'] = 'navigation'
            intent_result['confidence'] = 0.95
            intent_result['reasoning'].append('ูุจุญุซ ุนู ุตูุญุฉ ุฃู ููุงู')
        
        # 5. ุฃูุฑ ุชูููุฐู
        elif sentence_analysis['intent'] == 'command':
            intent_result['primary_intent'] = 'executable_command'
            intent_result['confidence'] = 0.8
            intent_result['reasoning'].append('ูุทูุจ ุชูููุฐ ุฅุฌุฑุงุก')
        
        # 6. ุทูุจ ุดุฑุญ
        elif any(w in text_lower for w in ['ูุง ูู', 'ูุง ูู', 'ุงุดุฑุญ', 'ุนุฑู']):
            intent_result['primary_intent'] = 'explanation_request'
            intent_result['confidence'] = 0.9
            intent_result['reasoning'].append('ูุทูุจ ุดุฑุญุงู ุฃู ุชุนุฑููุงู')
        
        # 7. ุญุณุงุจ ุฑูุงุถู
        elif sentence_analysis['entities'].get('number') or 'ุงุญุณุจ' in text_lower:
            intent_result['primary_intent'] = 'calculation'
            intent_result['confidence'] = 0.95
            intent_result['reasoning'].append('ูุทูุจ ุญุณุงุจุงู ุฑูุงุถูุงู')
        
        # ุฅุถุงูุฉ ุงูููุงูุง ุงูุซุงูููุฉ
        if semantic['is_temporal']:
            intent_result['secondary_intents'].append('time_scoped')
        if sentence_analysis['is_urgent']:
            intent_result['secondary_intents'].append('urgent')
        if sentence_analysis['is_polite']:
            intent_result['secondary_intents'].append('polite')
        
        return intent_result

# ==================== ูุนุงูุฌ ุงูุณูุงู ุงูุฐูู ====================

class ContextualProcessor:
    """ูุนุงูุฌ ุงูุณูุงู - ูููู ุงูุนูุงูุงุช ุจูู ุงูุฃุณุฆูุฉ"""
    
    def __init__(self):
        self.conversation_history = []
        self.current_topic = None
        self.mentioned_entities = set()
    
    def add_message(self, text: str, analysis: Dict[str, Any]):
        """ุฅุถุงูุฉ ุฑุณุงูุฉ ููุณูุงู"""
        self.conversation_history.append({
            'text': text,
            'analysis': analysis,
        })
        
        # ุชุญุฏูุซ ุงูููุงูุงุช ุงููุฐููุฑุฉ
        if 'entities' in analysis:
            for entity_type, values in analysis['entities'].items():
                self.mentioned_entities.add(entity_type)
        
        # ุชุญุฏูุซ ุงูููุถูุน ุงูุญุงูู
        if analysis.get('main_concept'):
            self.current_topic = analysis['main_concept']
    
    def resolve_references(self, text: str) -> str:
        """ุญู ุงูุถูุงุฆุฑ ูุงูุฅุดุงุฑุงุช"""
        # "ููู ูููู..." -> ูุนูุฏ ููููุงู ุงููุฐููุฑ ุณุงุจูุงู
        text_lower = text.lower()
        
        if any(ref in text_lower for ref in ['ูููู', 'ูููุง', 'ูุฐุง', 'ุฐูู', 'ุชูู']):
            if 'customer' in self.mentioned_entities:
                text = text.replace('ูููู', 'ูู ุงูุนููุงุก')
            elif 'product' in self.mentioned_entities:
                text = text.replace('ูููุง', 'ูู ุงูููุชุฌุงุช')
        
        return text
    
    def get_context_clues(self) -> Dict[str, Any]:
        """ุงูุญุตูู ุนูู ุฏูุงุฆู ุงูุณูุงู"""
        return {
            'current_topic': self.current_topic,
            'mentioned_entities': list(self.mentioned_entities),
            'conversation_length': len(self.conversation_history),
        }

# ==================== ุงููุญุฑู ุงูุฑุฆูุณู ====================

class IntelligentNLPEngine:
    """ูุญุฑู NLP ุงูุฐูู - ูุฌูุน ูู ุดูุก"""
    
    def __init__(self):
        self.intent_detector = AdvancedIntentDetector()
        self.context_processor = ContextualProcessor()
    
    def process(self, text: str) -> Dict[str, Any]:
        """ูุนุงูุฌุฉ ุฐููุฉ ูุงููุฉ ูููุต"""
        
        # 1. ุญู ุงูุฅุดุงุฑุงุช ูู ุงูุณูุงู
        resolved_text = self.context_processor.resolve_references(text)
        
        # 2. ูุดู ุงูููุฉ
        intent = self.intent_detector.detect_intent(resolved_text)
        
        # 3. ุชุญููู ุงูุฌููุฉ
        sentence = self.intent_detector.sentence_analyzer.analyze(resolved_text)
        
        # 4. ููู ุงููุนูู
        semantic = self.intent_detector.semantic_engine.understand_question(resolved_text)
        
        # 5. ุฏูุฌ ูู ุดูุก
        result = {
            'original_text': text,
            'resolved_text': resolved_text,
            'intent': intent,
            'sentence_structure': sentence,
            'semantic_meaning': semantic,
            'context': self.context_processor.get_context_clues(),
        }
        
        # 6. ุญูุธ ูู ุงูุณูุงู
        self.context_processor.add_message(text, result)
        
        return result
    
    def explain_understanding(self, result: Dict[str, Any]) -> str:
        """ุดุฑุญ ููู ููู ุงููุธุงู ุงูุณุคุงู"""
        explanation = f"""๐ง **ูููู ููุณุคุงู:**

๐ **ุงููุต:** {result['original_text']}

๐ฏ **ุงูููุฉ ุงูุฑุฆูุณูุฉ:** {result['intent']['primary_intent']}
   ุงูุซูุฉ: {result['intent']['confidence']*100:.0f}%

๐ญ **ุงูุณุจุจ:**
{chr(10).join(f'   โข {r}' for r in result['intent']['reasoning'])}

๐ **ุงูุชุญููู:**
   โข ุงูููููู: {result['semantic_meaning']['main_concept']}
   โข ููุน ุงูุณุคุงู: {'ููู' if result['semantic_meaning']['is_quantitative'] else 'ููุนู'}
   โข ูู ุจูุนุฏ ุฒููู: {'ูุนู' if result['semantic_meaning']['is_temporal'] else 'ูุง'}

๐ **ุงูุณูุงู:**
   โข ุงูููุถูุน ุงูุญุงูู: {result['context']['current_topic']}
   โข ุงูููุงูุงุช ุงููุฐููุฑุฉ: {', '.join(result['context']['mentioned_entities'][:5])}
"""
        return explanation

# ==================== ุงููุงุฌูุฉ ุงูุจุณูุทุฉ ====================

# ูุณุฎุฉ ุนุงูุฉ ููุงุณุชุฎุฏุงู
_global_nlp_engine = None

def get_nlp_engine():
    """ุงูุญุตูู ุนูู ูุญุฑู NLP ุงูุนุงู"""
    global _global_nlp_engine
    if _global_nlp_engine is None:
        _global_nlp_engine = IntelligentNLPEngine()
    return _global_nlp_engine

def understand_text(text: str, explain: bool = False) -> Dict[str, Any]:
    """ููู ุงููุต ุจุฐูุงุก
    
    Args:
        text: ุงููุต ุงููุฑุงุฏ ูููู
        explain: ูู ุชุฑูุฏ ุดุฑุญ ุงููููุ
    
    Returns:
        ุชุญููู ุฐูู ูุงูู
    """
    engine = get_nlp_engine()
    result = engine.process(text)
    
    if explain:
        result['explanation'] = engine.explain_understanding(result)
    return result

# ==================== ุงุฎุชุจุงุฑ ====================

if __name__ == '__main__':

    test_questions = [
        "ูู ุนุฏุฏ ุงูุนููุงุกุ",
        "ููู ูููู ุฏูุนูุงุ",  # ุณุคุงู ูุชุงุจุนุฉ
        "ุญูู ุฃุฏุงุก ุงููุจูุนุงุช",
        "ุงุญุณุจ VAT ูู 5000 ุดููู",
        "ููู ุตูุญุฉ ุงูุตูุงูุฉุ",
        "ูุง ุงููุฑู ุจูู ุงูุดุงูู ููุธุงูููุ",
    ]
    
    for q in test_questions:

        result = understand_text(q, explain=True)
